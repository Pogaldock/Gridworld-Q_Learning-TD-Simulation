# Project Summary

## Gridworld Q-Learning Temporal Difference Simulation

**Version:** 1.0.0  
**License:** MIT  
**Language:** Python 3.11+

### Overview

An interactive educational tool for learning and experimenting with Q-Learning and Temporal Difference (TD) reinforcement learning algorithms in a customizable gridworld environment.

### Key Features

âœ¨ **Interactive Grid Builder** - Design custom mazes with drag-and-drop interface  
ğŸ² **5 Maze Generators** - Recursive backtracking, binary tree, Prim's algorithm, open rooms, spiral  
ğŸ® **Real-time Training** - Watch Q-learning progress with terminal progress bar  
ğŸ“Š **Rich Visualizations** - Value heatmaps, policy arrows, episode animations  
ğŸ“ˆ **Performance Metrics** - Compare learned policy against optimal BFS path  
ğŸ§ª **Full Test Suite** - Unit tests for core components  
ğŸ—ï¸ **Modular Architecture** - Clean separation: env, agent, UI, config, utilities  
âš¡ **Performance Optimized** - Image caching for 60x speedup  

### Technology Stack

- **Core**: Python 3.11+
- **GUI**: Tkinter (built-in)
- **Visualization**: Matplotlib
- **Numerics**: NumPy
- **Testing**: Pytest

### Project Structure

```
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ agent.py             # Q-learning implementation
â”‚   â”œâ”€â”€ config.py            # Configuration constants
â”‚   â”œâ”€â”€ env.py               # Gridworld environment
â”‚   â”œâ”€â”€ maze_generators.py  # Maze generation algorithms
â”‚   â”œâ”€â”€ ui.py                # GUI components
â”‚   â””â”€â”€ utils.py             # Helper utilities
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ assets/                  # Images and resources
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ main.py                  # Entry point
â””â”€â”€ requirements.txt         # Dependencies
```

### Educational Value

Perfect for:
- ğŸ“ Learning reinforcement learning fundamentals
- ğŸ§  Understanding Q-learning algorithm
- ğŸ“š Teaching TD methods and exploration strategies
- ğŸ”¬ Experimenting with hyperparameters
- ğŸ’¡ Visualizing value functions and policies

### Quick Stats

- **Lines of Code**: ~2,000
- **Test Coverage**: Core components fully tested
- **Maze Algorithms**: 5 different generators
- **Visualization Types**: 4 (heatmaps, policies, animations, statistics)
- **Supported Grid Sizes**: 2Ã—2 to 100Ã—100

### Recent Improvements (v1.0.0)

âœ… Refactored into modular architecture  
âœ… Added image caching (60x performance boost)  
âœ… Created 5 maze generation algorithms  
âœ… Implemented terminal progress bar  
âœ… Added directional mouse icon with rotation  
âœ… Comprehensive documentation  
âœ… GitHub-ready structure  

### Use Cases

1. **Education** - Teaching RL concepts in university courses
2. **Research** - Quick prototyping of RL ideas
3. **Experimentation** - Testing different maze configurations
4. **Demonstration** - Showing how Q-learning works visually

### Future Enhancements

- [ ] Additional RL algorithms (SARSA, Expected SARSA)
- [ ] Deep Q-Learning (DQN) support
- [ ] Multi-agent scenarios
- [ ] Stochastic environments
- [ ] Export training data
- [ ] Web-based interface

### Links

- **Repository**: https://github.com/Pogaldock/Gridworld-Q_Learning-TD-Simulation
- **Issues**: Report bugs or request features
- **Discussions**: Ask questions and share ideas

### Citation

If you use this project in academic work, please cite:

```
Gridworld Q-Learning TD Simulation (2025)
https://github.com/Pogaldock/Gridworld-Q_Learning-TD-Simulation
```

### Acknowledgments

Built with educational goals in mind to make reinforcement learning accessible and visual.

---

**Made with â¤ï¸ for the RL community**
